{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual entailment with TensorFlow\n",
    "\n",
    "### Inspired by the O'Reilly article: <a href=\"https://www.oreilly.com/learning/textual-entailment-with-tensorflow\">Textual entailment with TensorFlow</a> Using neural networks to explore natural language.\n",
    "### By  Steven Hewitt - July 17, 2017\n",
    "GitHub code repo: https://github.com/Steven-Hewitt/Entailment-with-Tensorflow\n",
    "\n",
    "#### Note:\n",
    "> This derived Notebook «Textual_Entailment_with_TensorFlow.ipynb» is a small contribution by Claude COULOMBE, PhD candidate, TÉLUQ / UQAM. The Notebook is running fine but the results are weak. Probably, you should train the model longer on more data.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Textual entailment is a simple exercise in logic that attempts to discern whether one sentence can be inferred from another. A computer program that takes on the task of textual entailment attempts to categorize an ordered pair of sentences into one of three categories. The first category, called “positive entailment,” occurs when you can use the first sentence to prove that a second sentence is true. The second category, “negative entailment,” is the inverse of positive entailment. This occurs when the first sentence can be used to disprove the second sentence. Finally, if the two sentences have no correlation, they are considered to have a “neutral entailment.”\n",
    "\n",
    "> Textual Entailment is the task of determining whether a piece of text \"R\" for reference text accepted as truth involves another text called \"H\" for hypothesis text to be accepted as true, false, or indeterminable.\n",
    "\n",
    "Textual entailment is useful as a component in much larger applications. For example, question-answering systems may use textual entailment to verify an answer from stored information. Textual entailment may also enhance document summarization by filtering out sentences that don’t include new information. Other natural language processing (NLP) systems find similar uses for entailment.\n",
    "\n",
    "This article will guide you through how to build a simple and fast-to-train neural network to perform textual entailment using TensorFlow.\n",
    "\n",
    "### Examples of textual entailment\n",
    "\n",
    "In this section, we’ll walk through a few examples of textual entailment to illustrate what we mean by positive, negative, and neutral entailment. To begin, we’ll look at positive entailment—when you read, for example, that “Maurita and Jade both were at the scene of the car crash,” you can infer that “Multiple people saw the accident.” In this example sentence pair, we can prove the second sentence (also known as a “hypothesis”) from the first sentence (also called the “reference”), meaning that this represents a positive entailment. Given that Maurita and Jade were both there to view the crash, multiple people must have seen it. Note: “car crash” and “accident” have similar meanings, but they aren’t the same word. In fact, entailment doesn’t always mean that the sentences share words, as can be seen in this sentence pair, which only shares the word “the.”\n",
    "\n",
    "Let’s consider another sentence pair. How, if at all, does the sentence “Two dogs played in the park with the old man” entail “There was only one canine in the park that day”? If there are two dogs, there must be at least two canines. Since the second sentence contradicts that idea, this is negative entailment.\n",
    "\n",
    "Finally, to illustrate neutral entailment, we consider, how, if at all, the sentence “I played baseball with the kids” entails “The kids love ice cream.” Playing baseball and loving ice cream have absolutely nothing to do with each other. I could play baseball with ice cream lovers, and I could play baseball with ice cream haters (both are equally possible). Thus, the first sentence says nothing about the truth or falsehood of the second—implying neutral entailment.\n",
    "\n",
    "<img src=\"https://d3ansictanv2wj.cloudfront.net/Figure_1-5c0c18591e46fb09c6f5ea7bf33c56fe.jpg\"/>\n",
    "<!-- <img src=\"images/Figure_1.jpg\"/> -->\n",
    "Figure 1. Types of entailment. Credit: Steven Hewitt.\n",
    "\n",
    "### Representing words as numbers using word vectorization\n",
    "\n",
    "Unfortunately for neural networks, they primarily work with numeric values. To get around this, we need to represent our words as numbers in some way. Ideally, these numbers mean something; for example, we could use the character codes of the letters in a word, but that doesn’t tell us anything about the meaning of it (which would mean that TensorFlow would have to do a lot of work to tell that “dog” and “canine” are close to the same concept). Turning similar meanings into something a neural network can understand happens by a process called word vectorization.\n",
    "\n",
    "One common way to create word vectorizations is to have each word represent a single point in a very high-dimensional space. Words with similar representations should be relatively close together in this space. For example, each color has a representation that is usually very similar to other colors; demonstrations of this can be found in the <a href=\"https://www.tensorflow.org/tutorials/word2vec\">TensorFlow tutorial on word vectorization</a>.\n",
    "\n",
    "### Working with Stanford’s GloVe word vectorization + SNLI data set\n",
    "\n",
    "For our purposes, we won’t need to create a new representation of words as numbers. There already exist quite a few fantastic general-purpose vector representations of words as well as ways to train even more specialized material if the general-purpose data isn’t enough.\n",
    "\n",
    "The associated notebook for this article is designed to work with the <a href=\"http://nlp.stanford.edu/projects/glove/\">pre-trained data for Stanford’s GloVe word vectorization</a>. We’ll be using the six-billion-token Wikipedia 2014 + Gigaword 5 vectors, since it’s the smallest and easiest to download. We’ll download the file programmatically, but keep in mind that it may take a while to run (it’s a fairly large file).\n",
    "\n",
    "At the same time, we'll also be picking up our data set for textual entailment: <a href=\"http://nlp.stanford.edu/projects/snli/\">Stanford’s SNLI data set</a>. We'll be using the development set in the interest of speed (it has only 10,000 sentence pairs), but if you're interested in getting better results and have time to spare for training, you can try using the full data set instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get started\n",
    "\n",
    "In addition to installing TensorFlow version 1.0, make sure you’ve installed each of the following:\n",
    "\n",
    "* Jupyter\n",
    "* Numpy\n",
    "* Matplotlib\n",
    "\n",
    "To get a better sense of progress during network training, you're also welcome to install TQDM (`pip3 install tqdm`), but it's not required. Please access the code and Jupyter Notebook for this article on GitHub. We’ll be using <a href=\"http://nlp.stanford.edu/projects/snli/\">Stanford’s SNLI data set</a> for our training, but we’ll download and extract the data we need using code from the Jupyter Notebook, so you don’t need to download it manually. If this is your first time working with TensorFlow, I’d encourage you to check out Aaron Schumacher’s article, <a href=\"https://www.oreilly.com/learning/hello-tensorflow\">“Hello, Tensorflow.”</a>\n",
    "\n",
    "We’ll start by doing all necessary imports, and we’ll let our Jupyter Notebook know that it should display graphs and images in the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python packages imported\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "print(\"Python packages imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data download\n",
    "\n",
    "The files we're about to use may take five minutes or more to download, so if you're following along by running the program in the corresponding notebook, feel free to start running the next few cells. In the meantime, let’s explore textual entailment in further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "snli_zip_file = \"snli_1.0.zip\"\n",
    "snli_dev_file = \"snli_1.0_dev.txt\"\n",
    "snli_full_dataset_file = \"snli_1.0_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded\n"
     ]
    }
   ],
   "source": [
    "from six.moves.urllib.request import urlretrieve\n",
    "    \n",
    "#large file - 862 MB\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "\n",
    "#medium-sized file - 94.6 MB\n",
    "if (not os.path.isfile(snli_zip_file) and\n",
    "    not os.path.isfile(snli_dev_file)):\n",
    "    urlretrieve (\"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\", \n",
    "                 snli_zip_file)\n",
    "\n",
    "print(\"Data downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uncompressed\n"
     ]
    }
   ],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "unzip_single_file(snli_zip_file, snli_dev_file)\n",
    "# unzip_single_file(snli_zip_file, snli_full_dataset_file)\n",
    "\n",
    "print(\"Data uncompressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up a GloVe dictionary\n",
    "Now that we have our GloVe vectors downloaded, we can load them into memory, deserializing the space separated format into a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe dictionary set-up\n"
     ]
    }
   ],
   "source": [
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")\n",
    "\n",
    "print(\"GloVe dictionary set-up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform input sentence to sequence of GloVe word-vectors\n",
    "Once we have our words, we need our input to contain entire sentences and process it through a neural network. Let's start with making the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to transform input sentence to sequence ready\n"
     ]
    }
   ],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "     \n",
    "    - Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "    \n",
    "      Tensorflow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      Tensorflow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "            else:\n",
    "                i = i-1\n",
    "    return rows, words\n",
    "\n",
    "print(\"Function to transform input sentence to sequence ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the computer sees when it looks at a sentence?\n",
    "\n",
    "To better visualize the word vectorization process, and to see what the computer sees when it looks at a sentence, we can represent the vectors as images. Feel free to use the notebook to play around with visualizing your own sentences. Each row represents a single word, and the columns represent individual dimensions of the vectorized word. The vectorizations are trained in terms of relationships to other words, so what the representations actually mean is ambiguous. The computer can understand this vector language, and that’s the most important part to us. Generally speaking, two vectors that contain similar colors in the same positions represent words that are similar in meaning.\n",
    "\n",
    "<img src=\"https://d3ansictanv2wj.cloudfront.net/Figure_2-3b82d4aee8a7bf022dbb6c05ff40af8b.jpg\"/>\n",
    "<!-- <img src=\"images/Figure_2.jpg\"/> -->\n",
    "\n",
    "<center>Figure 2. Sentences in vectorized form, visualized. Credit: Steven Hewitt.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEyCAYAAAD3BqoNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2VAMX4IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122d73d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAEyCAYAAAAcMREOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nruEFGfdlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128a4b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(sentence):\n",
    "    rows, words = sentence2sequence(sentence)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "#   shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    shown = ax.matshow(mat, cmap='coolwarm', aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()\n",
    "    \n",
    "visualize(\"The quick brown fox jumped over the lazy dog.\")\n",
    "visualize(\"The pretty flowers shone in the sunlight.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up the neural network\n",
    "\n",
    "Unlike images, sentences are inherently sequential and can’t be constrained by size, so instead of fully connected forward-feeding networks that take in one input value and simply run until it produces a single output, we need a new type of network. We need...recurrence.\n",
    "\n",
    "#### Vanilla recurrent networks\n",
    "\n",
    "Recurrent Neural Networks (also known as RNNs) are a sequence-learning tool for neural networks. This type of neural network has only one layer’s worth of hidden inputs, which is re-used for each input from the sequence, along with a “memory” that’s passed ahead to the next input’s calculations. These are calculated using matrix multiplication where the matrix indices are trained weights, just like they are in a fully-connected layer. \n",
    "\n",
    "The same calculations are repeated for each input in the sequence, meaning that a single “layer” of a recurrent neural network can be unrolled into many layers. In fact, there will be as many layers as there are inputs in the sequence. This allows the network to process a very complex sentence. TensorFlow includes its own implementation of a vanilla RNN cell, `BasicRNNCell`, which can be added to your TensorFlow graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_size = 64\n",
    "rnn = tf.contrib.rnn.BasicRNNCell(rnn_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vanishing gradient problem\n",
    "\n",
    "In theory, the network would be able to remember things from one of the first layers, much earlier in the sentence—even at the end of the sentence. The main problem with this form of recurrence is that, in practice, earlier data is completely drowned out by newer inputs and information that doesn’t end up being nearly as important. Recurrent neural networks, or at least a neural network with standard hidden units, often fail to hold on to information for long periods of time. This failure is known as the vanishing gradient problem.\n",
    "\n",
    "The simplest way to visualize this is by example. In the simplest case, input and “memory” are roughly equally weighted. The first input into the data will affect approximately half of the first output (the other half being the starting “memory”), a quarter of the second output, then an eighth of the third output, and so on.\n",
    "\n",
    "This means we can’t use vanilla recurrent networks, at least not if we want to keep track of both sentences in this pair. The solution is to use a different type of recurrent network layer. Perhaps the simplest of these is the long short-term memory layer, also known as an LSTM.\n",
    "\n",
    "#### Utilizing LSTM\n",
    "\n",
    "In an LSTM, instead of the input ($x_t$) always being used the same way every time in the calculation of current memory, the network makes a decision on how much the current values can affect the memory by an “input gate” (it), and makes another decision on what memory (ct) is forgotten by an appropriately named “forget gate” (ft), and finally makes a third decision on what parts of memory are sent to the next timestep (ht) by an “output gate” (ot).\n",
    "\n",
    "<img src=\"https://d3ansictanv2wj.cloudfront.net/Figure_3-91a9d52b6ce666c7b66f2a046221ff80.jpg\"/>\n",
    "\n",
    "<center>Figure 3. A diagram showing the hidden units within an LSTM layer. Credit: Steven Hewitt<br/> (adapted from this <a href=\"https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:Long_Short_Term_Memory.png\">similar image</a>, distributed under CC BY-SA 4.0).</center>\n",
    "<!-- <img src=\"images/Figure_3.jpg\" width=500/> -->\n",
    "\n",
    "The combination of these three gates creates a choice: a single LSTM node can either keep information in long-term memory or keep it in short-term memory, but it can’t do both at the same time. Short-term memory LSTMs usually train to have relatively open input gates that let a lot of information in and forget many things often, while long-term memory LSTMs have tight input gates that only allow very small, very specific pieces of information in. This tightness means that it doesn’t lose its information easily, allowing for longer retention time.\n",
    "\n",
    "In general, LSTMs are very cryptic. Different LSTM nodes in the same network may have vastly different gates that rely upon one another, such as perhaps having a short-term gate remember the word “not” in the sentence “John did not go to the store,” so that when the word “go” appears, a long-term gate could remember “not go” instead of “go.” Of course, this is a contrived example, and, in practice, these relationships are very complex to the point of being indecipherable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Defining the hyperparameters for our network\n",
    "\n",
    "Since we aren’t going to use a vanilla RNN layer in our network, let's clear out the graph and add an LSTM layer, which TensorFlow also includes by default. This is going to be the first part of our actual network, let's also define all the hyperparameters (aka constants) we'll need for the network, which we'll talk about as they come up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters set-up\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters setup\n",
    "max_hypothesis_length, max_evidence_length = 30, 30\n",
    "batch_size, vector_size, hidden_size = 128, 50, 64\n",
    "\n",
    "lstm_size = hidden_size\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "training_iterations_count = 100000\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "def score_setup(row):\n",
    "    convert_dict = {\n",
    "      'entailment': 0,\n",
    "      'neutral': 1,\n",
    "      'contradiction': 2\n",
    "    }\n",
    "    score = np.zeros((3,))\n",
    "    for x in range(1,6):\n",
    "        tag = row[\"label\"+str(x)]\n",
    "        if tag in convert_dict: score[convert_dict[tag]] += 1\n",
    "    return score / (1.0*np.sum(score))\n",
    "\n",
    "def fit_to_size(matrix, shape):\n",
    "    res = np.zeros(shape)\n",
    "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\n",
    "    res[slices] = matrix[slices]\n",
    "    return res\n",
    "\n",
    "print(\"Hyperparameters set-up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted\n"
     ]
    }
   ],
   "source": [
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"snli_1.0_dev.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data, delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence1\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence2\"].lower())[0]))\n",
    "            labels.append(row[\"gold_label\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "    \n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "l_h, l_e = max_hypothesis_length, max_evidence_length\n",
    "N, D, H = batch_size, vector_size, hidden_size\n",
    "l_seq = l_h + l_e\n",
    "\n",
    "print(\"Data splitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also reset the graph to not include the RNN cell we added earlier, since we won't be using that for this network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both those out of the way, we can define our LSTM using TensorFlow as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing dropout, for regularization\n",
    "\n",
    "If we simply used LSTM layers and nothing more, the network might read a lot of meaning into common, but inconsequential, words like “a,” “the,” and “and.” The network might incorrectly believe that it has found negative entailment if one sentence uses the phrase “an animal” and the other uses “the animal,” even if those phrases refer to the same object.\n",
    "\n",
    "To solve this, we need to regulate to see if individual words end up being important to the meaning as a whole, and we do that by a process called “dropout.” Dropout is a regularization pattern in neural network design that revolves around dropping randomly selected hidden and visible units. As the size of a neural network increases, so does the number of parameters used to calculate the final result, each of which contributes to overfitting if trained all at once. In order to regularize for this, a portion of the units contained within the network are selected randomly and zeroed out temporarily during training, and their outputs are scaled appropriately during actual use.\n",
    "\n",
    "Dropout on “standard” (i.e., fully connected) layers is also useful because it effectively trains multiple smaller networks, and then combines them during testing time. One of the constants in machine learning is that combining multiple models nearly always makes for a better method than a single model on its own, and dropout serves to turn a single neural network into multiple smaller neural networks that share some nodes, and thus some parameters, with the others.\n",
    "\n",
    "A dropout layer has one hyperparameter known as p, which is simply the probability that each unit is kept in the network for that iteration of training. The units that are kept provide their outputs to the next layer, and the units that are not kept provide nothing. What follows is an example showing the difference between a fully connected network without dropout and a fully connected network with dropout during one iteration of training:\n",
    "\n",
    "<img src=\"https://d3ansictanv2wj.cloudfront.net/Figure_4-d25389effee015dafb164e004d8e2db6.jpg\"/>\n",
    "<!-- <img src=\"images/Figure_4.jpg\" width=600/> --> \n",
    "<center>Figure 4. On the left: A normal fully connected network. On the right: The same network during training, with p = 0.5.<br/>(Credit: Steven Hewitt)</center>\n",
    "\n",
    "#### Tensorflow’s DropoutWrapper for recurrent layers\n",
    "\n",
    "Unfortunately, dropout does not play particularly nicely with LSTM layers' internal gates. The loss of certain pieces of crucial memory means that complicated relationships required for first-order logic have a harder time forming with dropout, so for our LSTM layer, we’ll skip using dropout on internal gates, instead using it on everything else.  Thankfully, this is the default implementation of <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper\">Tensorflow’s DropoutWrapper</a> for recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_drop =  tf.contrib.rnn.DropoutWrapper(lstm, input_p, output_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completing our neural network model\n",
    "\n",
    "With all the explanations out of the way, we can finish up our model. The first step is tokenizing and using our GloVe dictionary to turn the two input sentences into a single sequence of vectors. Since we can’t effectively use dropout on information that gets passed within an LSTM, we’ll use dropout on features from words, and on final output instead -- effectively using dropout on the first and last layers from the unrolled LSTM network portions. \n",
    "\n",
    "You may notice that we use a bi-directional RNN, with two different LSTM units. This form of recurrent network runs both forward and backward through the input data, which allows the network to review both the hypothesis and the evidence (or reference) both independently and in relation to each other.\n",
    "\n",
    "The final output from the LSTMs will be passed into a set of fully connected layers, and then from that we’ll get a single real-valued score that indicates how strong each of the kinds of entailment are, which we use to select our final result and our confidence in that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N: The number of elements in each of our batches, \n",
    "#   which we use to train subsets of data for efficiency's sake.\n",
    "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\n",
    "#   used because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# l_e: The maximum length of evidence, the first sentence.  This is used\n",
    "#   because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# D: The size of our used GloVe or other vectors.\n",
    "hyp = tf.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\n",
    "evi = tf.placeholder(tf.float32, [N, l_e, D], 'evidence')\n",
    "y = tf.placeholder(tf.float32, [N, 3], 'label')\n",
    "# hyp: Where the hypotheses will be stored during training.\n",
    "# evi: Where the evidences will be stored during training.\n",
    "# y: Where correct scores will be stored during training.\n",
    "\n",
    "# lstm_size: the size of the gates in the LSTM, \n",
    "#    as in the first LSTM layer's initialization.\n",
    "lstm_back = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# lstm_back:  The LSTM used for looking backwards \n",
    "#   through the sentences, similar to lstm.\n",
    "\n",
    "# input_p: the probability that inputs to the LSTM will be retained at each\n",
    "#   iteration of dropout.\n",
    "# output_p: the probability that outputs from the LSTM will be retained at \n",
    "#   each iteration of dropout.\n",
    "lstm_drop_back = tf.contrib.rnn.DropoutWrapper(lstm_back, input_p, output_p)\n",
    "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\n",
    "\n",
    "fc_initializer = tf.random_normal_initializer(stddev=0.1) \n",
    "# fc_initializer: initial values for the fully connected layer's weights.\n",
    "# hidden_size: the size of the outputs from each lstm layer.  \n",
    "#   Multiplied by 2 to account for the two LSTMs.\n",
    "fc_weight = tf.get_variable('fc_weight', [2*hidden_size, 3], \n",
    "                            initializer = fc_initializer)\n",
    "# fc_weight: Storage for the fully connected layer's weights.\n",
    "fc_bias = tf.get_variable('bias', [3])\n",
    "# fc_bias: Storage for the fully connected layer's bias.\n",
    "\n",
    "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\n",
    "#   designated for losses due to regularization.\n",
    "#   In this case, this portion of loss is regularization on the weights\n",
    "#   for the fully connected layer.\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(fc_weight)) \n",
    "\n",
    "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\n",
    "# Permuting batch_size and n_steps\n",
    "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x = tf.split(x, l_seq,)\n",
    "\n",
    "# x: the inputs to the bidirectional_rnn\n",
    "\n",
    "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\n",
    "#   two recurrent networks, one that runs the inputs forward and one\n",
    "#   that runs the inputs in reversed order, combining the outputs.\n",
    "rnn_outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm, lstm_back,\n",
    "                                                            x, dtype=tf.float32)\n",
    "# rnn_outputs: the list of LSTM outputs, as a list. \n",
    "#   What we want is the latest output, rnn_outputs[-1]\n",
    "\n",
    "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\n",
    "# The scores are relative certainties for how likely the output matches\n",
    "#   a certain entailment: \n",
    "#     0: Positive entailment\n",
    "#     1: Neutral entailment\n",
    "#     2: Negative entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing TensorFlow how to calculate loss and accuracy\n",
    "\n",
    "In order to test the accuracy and begin to add in optimization constraints, we need to show TensorFlow how to calculate the accuracy, or -- the percentage of correctly predicted labels.\n",
    "\n",
    "We also need to determine a loss, to show how poorly the network is doing. Since we have both classification scores and optimal scores, the choice here is using a variation on softmax loss from Tensorflow: `tf.nn.softmax_cross_entropy_with_logits`. We add in regularization losses to help with overfitting, and then prepare an optimizer to learn how to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\n",
    "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, y_label)\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = classification_scores, labels = y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    total_loss = loss + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Finally, we can train the network! If you installed TQDM, you can use it to keep track of progress as the network trains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/782 [00:00<07:23,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss= 1.088066, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/782 [00:02<01:47,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10.0, Minibatch Loss= 1.100138, Training Accuracy= 0.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 22/782 [00:03<01:30,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20.0, Minibatch Loss= 1.084840, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 32/782 [00:04<01:45,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30.0, Minibatch Loss= 1.096247, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 42/782 [00:05<01:53,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40.0, Minibatch Loss= 1.093393, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 53/782 [00:07<01:27,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50.0, Minibatch Loss= 1.090575, Training Accuracy= 0.37500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 63/782 [00:08<01:22,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60.0, Minibatch Loss= 1.088268, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 73/782 [00:09<01:24,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70.0, Minibatch Loss= 1.076672, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 83/782 [00:10<01:16,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80.0, Minibatch Loss= 1.096250, Training Accuracy= 0.35156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 93/782 [00:11<01:16,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90.0, Minibatch Loss= 1.085249, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 102/782 [00:12<01:38,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100.0, Minibatch Loss= 1.078328, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 113/782 [00:14<01:34,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110.0, Minibatch Loss= 1.070820, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 122/782 [00:15<01:31,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120.0, Minibatch Loss= 1.081748, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 132/782 [00:17<01:35,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130.0, Minibatch Loss= 1.052584, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 143/782 [00:18<01:25,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140.0, Minibatch Loss= 1.064394, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 152/782 [00:19<01:31,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150.0, Minibatch Loss= 1.088482, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 162/782 [00:21<01:34,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160.0, Minibatch Loss= 1.098563, Training Accuracy= 0.36719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 172/782 [00:22<01:22,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170.0, Minibatch Loss= 1.064505, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 182/782 [00:23<01:11,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180.0, Minibatch Loss= 1.080027, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 193/782 [00:25<01:12,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190.0, Minibatch Loss= 1.091725, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 202/782 [00:26<01:26,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200.0, Minibatch Loss= 1.041403, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 212/782 [00:28<01:36,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210.0, Minibatch Loss= 1.078522, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 221/782 [00:29<01:16,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220.0, Minibatch Loss= 1.082905, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 232/782 [00:30<01:34,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230.0, Minibatch Loss= 1.083336, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 242/782 [00:32<01:22,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240.0, Minibatch Loss= 1.074814, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 252/782 [00:33<01:13,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250.0, Minibatch Loss= 1.077455, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 261/782 [00:34<01:12,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260.0, Minibatch Loss= 1.078841, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 273/782 [00:36<01:01,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270.0, Minibatch Loss= 1.088600, Training Accuracy= 0.37500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 282/782 [00:37<01:10,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280.0, Minibatch Loss= 1.069690, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 292/782 [00:38<01:02,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290.0, Minibatch Loss= 1.077397, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 302/782 [00:39<01:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300.0, Minibatch Loss= 1.076930, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 312/782 [00:41<01:01,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310.0, Minibatch Loss= 1.081758, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 323/782 [00:42<01:03,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320.0, Minibatch Loss= 1.060830, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 333/782 [00:43<01:01,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330.0, Minibatch Loss= 1.071990, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 343/782 [00:45<01:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340.0, Minibatch Loss= 1.043315, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 352/782 [00:46<01:02,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350.0, Minibatch Loss= 1.062797, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 362/782 [00:47<00:56,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360.0, Minibatch Loss= 1.042565, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 373/782 [00:49<00:47,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370.0, Minibatch Loss= 1.066197, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 383/782 [00:50<00:46,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380.0, Minibatch Loss= 1.020965, Training Accuracy= 0.53906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 392/782 [00:51<00:49,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390.0, Minibatch Loss= 1.046218, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 403/782 [00:52<00:39,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400.0, Minibatch Loss= 1.045308, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 413/782 [00:53<00:36, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410.0, Minibatch Loss= 1.038693, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 423/782 [00:54<00:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420.0, Minibatch Loss= 1.055968, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 433/782 [00:55<00:33, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430.0, Minibatch Loss= 1.037158, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 443/782 [00:56<00:32, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440.0, Minibatch Loss= 1.054733, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 453/782 [00:57<00:34,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450.0, Minibatch Loss= 1.066701, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 461/782 [00:58<00:35,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460.0, Minibatch Loss= 2.052315, Training Accuracy= 0.29688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 472/782 [00:59<00:33,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470.0, Minibatch Loss= 1.093284, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 483/782 [01:00<00:39,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 480.0, Minibatch Loss= 1.029379, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 493/782 [01:01<00:36,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490.0, Minibatch Loss= 1.077508, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 503/782 [01:03<00:32,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500.0, Minibatch Loss= 1.055784, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 512/782 [01:04<00:35,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510.0, Minibatch Loss= 1.077108, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 523/782 [01:05<00:27,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520.0, Minibatch Loss= 1.077881, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 533/782 [01:06<00:30,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530.0, Minibatch Loss= 1.023267, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 541/782 [01:07<00:28,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 540.0, Minibatch Loss= 1.016126, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 553/782 [01:08<00:29,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550.0, Minibatch Loss= 1.051720, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 561/782 [01:09<00:27,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560.0, Minibatch Loss= 1.012270, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 573/782 [01:11<00:24,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570.0, Minibatch Loss= 1.053488, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 582/782 [01:12<00:30,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 580.0, Minibatch Loss= 1.021688, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 593/782 [01:13<00:24,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590.0, Minibatch Loss= 1.044932, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 602/782 [01:14<00:22,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600.0, Minibatch Loss= 1.030654, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 612/782 [01:15<00:18,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610.0, Minibatch Loss= 1.019260, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 621/782 [01:16<00:21,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 620.0, Minibatch Loss= 1.016721, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 633/782 [01:18<00:16,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630.0, Minibatch Loss= 1.020480, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 643/782 [01:19<00:16,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640.0, Minibatch Loss= 1.017708, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 651/782 [01:20<00:18,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650.0, Minibatch Loss= 1.015517, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 662/782 [01:21<00:13,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 660.0, Minibatch Loss= 1.014639, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 672/782 [01:22<00:13,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670.0, Minibatch Loss= 1.034306, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 683/782 [01:23<00:10,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 680.0, Minibatch Loss= 1.039952, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 692/782 [01:24<00:11,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690.0, Minibatch Loss= 1.064102, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 703/782 [01:25<00:08,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700.0, Minibatch Loss= 0.992308, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 712/782 [01:26<00:08,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710.0, Minibatch Loss= 1.053722, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 723/782 [01:28<00:06,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 720.0, Minibatch Loss= 1.007184, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 733/782 [01:29<00:04,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730.0, Minibatch Loss= 1.037127, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 742/782 [01:30<00:04,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 740.0, Minibatch Loss= 1.050359, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 751/782 [01:31<00:03,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750.0, Minibatch Loss= 1.044975, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 762/782 [01:32<00:02,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 760.0, Minibatch Loss= 1.038653, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 773/782 [01:33<00:01,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770.0, Minibatch Loss= 0.985656, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [01:34<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 780.0, Minibatch Loss= 1.016005, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Launch the Tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "training_iterations = range(0,training_iterations_count,batch_size)\n",
    "if tqdm_installed:\n",
    "    # Add a progress bar if TQDM is installed\n",
    "    training_iterations = tqdm(training_iterations)\n",
    "\n",
    "for i in training_iterations:\n",
    "\n",
    "    # Select indices for a random data subset\n",
    "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\n",
    "    \n",
    "    # Use the selected subset indices to initialize the graph's \n",
    "    #   placeholder values\n",
    "    hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                      data_feature_list[1][batch,:],\n",
    "                      correct_scores[batch])\n",
    "    \n",
    "    # Run the optimization with these initialized values\n",
    "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "    # display_step: how often the accuracy and loss should \n",
    "    #   be tested and displayed.\n",
    "    if (i/batch_size) % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Calculate batch loss\n",
    "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Display results\n",
    "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Your network is now trained! You should see accuracies around 50-55%, which can be improved by careful modification of hyperparameters and increasing the dataset size to include the entire training set. Usually, this will correspond with an increase in training time.\n",
    "\n",
    "Feel free to modify the following code by inserting your own sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative entailment\n"
     ]
    }
   ],
   "source": [
    "# evidences = [\"Maurita and Jade both were at the scene of the car crash.\"]\n",
    "# hypotheses = [\"Multiple people saw the accident.\"]\n",
    "# Negative entailment WRONG!\n",
    "\n",
    "# evidences = [\"John is a man and Janet is a woman\"]\n",
    "# hypotheses = [\"There is two people\"]\n",
    "# Positive entailment\n",
    "\n",
    "# evidences = [\"Socrate is a man and all man are mortal\"]\n",
    "# hypotheses = [\"Socrate is mortal\"]\n",
    "# Positive entailment\n",
    "\n",
    "# evidences = [\"Socrate is a man and all man are mortal\"]\n",
    "# hypotheses = [\"Socrate is washing dishes\"]\n",
    "# Positive entailment\n",
    "\n",
    "# evidences = [\"Socrate is a man who plays golf\"]\n",
    "# hypotheses = [\"He is a sportman\"]\n",
    "# Positive entailment\n",
    "\n",
    "# evidences = [\"Socrate gave a man a shot\"]\n",
    "# hypotheses = [\"The sky is blue\"]\n",
    "# Negative entailment\n",
    "\n",
    "# evidences = [\"Two dogs played in the park with the old man\"]\n",
    "# hypotheses = [\"There was only one canine in the park that day\"]\n",
    "# Neutral entailment\n",
    "\n",
    "# evidences = [\"I played baseball with the kids\"]\n",
    "# hypotheses = [\"The kids love ice cream\"]\n",
    "# Negative entailment\n",
    "\n",
    "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\n",
    "                         (30, 50)) for evidence in evidences]\n",
    "\n",
    "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\n",
    "                         (30,50)) for hypothesis in hypotheses]\n",
    "\n",
    "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\n",
    "                                                        evi: (sentence2 * N),\n",
    "                                                        y: [[0,0,0]]*N})\n",
    "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\n",
    "      \" entailment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we're done playing with our model, we'll close the session to free up system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interested in developing more results?\n",
    "\n",
    "The design focus of this network was creating a simple system that was easy and quick to train. In order to get more accurate results, you may want to consider:\n",
    "\n",
    "* Adding more layers of LSTMs.\n",
    "* Using alternative types of RNN layers, such as Gated Recurrent Units (GRUs). TensorFlow also includes an implementation of GRUs.\n",
    "* Adding more hidden units. If you do this, increase regularization and dropout strengths to account for the fact that there are more parameters in the network.\n",
    "* Experimentation with other kinds of networks entirely!\n",
    "\n",
    "This post is a collaboration between O'Reilly and TensorFlow. See our statement of editorial independence.\n",
    "\n",
    "Steven Hewitt is currently a graduate student in the Computer Science division of the EECS department at the University of California, Berkeley. His academic interests include AI, natural language processing, education, and robotics. His research endeavors currently include teaching programs to understand code patterns and display them in a way relevant to humans, word embedding methods, and question-answering systems. When he’s not attending classes or coding, you may find him composing music or generating fractal flame art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
